{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ac635f0",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f04062f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: unsloth in /home/chengyi/anaconda3/envs/rag/lib/python3.11/site-packages (2026.1.4)\n",
      "Requirement already satisfied: rich in /home/chengyi/anaconda3/envs/rag/lib/python3.11/site-packages (14.3.2)\n",
      "Requirement already satisfied: unsloth_zoo>=2026.1.4 in /home/chengyi/anaconda3/envs/rag/lib/python3.11/site-packages (from unsloth) (2026.1.4)\n",
      "Requirement already satisfied: wheel>=0.42.0 in /home/chengyi/anaconda3/envs/rag/lib/python3.11/site-packages (from unsloth) (0.45.1)\n",
      "Requirement already satisfied: packaging in /home/chengyi/anaconda3/envs/rag/lib/python3.11/site-packages (from unsloth) (26.0)\n",
      "Requirement already satisfied: torch>=2.4.0 in /home/chengyi/anaconda3/envs/rag/lib/python3.11/site-packages (from unsloth) (2.10.0)\n",
      "Requirement already satisfied: torchvision in /home/chengyi/anaconda3/envs/rag/lib/python3.11/site-packages (from unsloth) (0.25.0)\n",
      "Requirement already satisfied: numpy in /home/chengyi/anaconda3/envs/rag/lib/python3.11/site-packages (from unsloth) (2.4.1)\n",
      "Requirement already satisfied: tqdm in /home/chengyi/anaconda3/envs/rag/lib/python3.11/site-packages (from unsloth) (4.67.1)\n",
      "Requirement already satisfied: psutil in /home/chengyi/anaconda3/envs/rag/lib/python3.11/site-packages (from unsloth) (7.2.1)\n",
      "Requirement already satisfied: tyro in /home/chengyi/anaconda3/envs/rag/lib/python3.11/site-packages (from unsloth) (1.0.6)\n",
      "Requirement already satisfied: protobuf in /home/chengyi/anaconda3/envs/rag/lib/python3.11/site-packages (from unsloth) (6.33.5)\n",
      "Collecting xformers>=0.0.27.post2 (from unsloth)\n",
      "  Using cached xformers-0.0.34-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5 in /home/chengyi/anaconda3/envs/rag/lib/python3.11/site-packages (from unsloth) (0.49.1)\n",
      "Requirement already satisfied: triton>=3.0.0 in /home/chengyi/anaconda3/envs/rag/lib/python3.11/site-packages (from unsloth) (3.6.0)\n",
      "Requirement already satisfied: sentencepiece>=0.2.0 in /home/chengyi/anaconda3/envs/rag/lib/python3.11/site-packages (from unsloth) (0.2.1)\n",
      "Requirement already satisfied: datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1 in /home/chengyi/anaconda3/envs/rag/lib/python3.11/site-packages (from unsloth) (4.3.0)\n",
      "Requirement already satisfied: accelerate>=0.34.1 in /home/chengyi/anaconda3/envs/rag/lib/python3.11/site-packages (from unsloth) (1.12.0)\n",
      "Requirement already satisfied: peft!=0.11.0,>=0.18.0 in /home/chengyi/anaconda3/envs/rag/lib/python3.11/site-packages (from unsloth) (0.18.1)\n",
      "Requirement already satisfied: huggingface_hub>=0.34.0 in /home/chengyi/anaconda3/envs/rag/lib/python3.11/site-packages (from unsloth) (0.36.0)\n",
      "Requirement already satisfied: hf_transfer in /home/chengyi/anaconda3/envs/rag/lib/python3.11/site-packages (from unsloth) (0.1.9)\n",
      "Requirement already satisfied: diffusers in /home/chengyi/anaconda3/envs/rag/lib/python3.11/site-packages (from unsloth) (0.36.0)\n",
      "Requirement already satisfied: transformers!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,!=4.54.0,!=4.55.0,!=4.55.1,!=4.57.0,!=4.57.4,!=4.57.5,<=4.57.6,>=4.51.3 in /home/chengyi/anaconda3/envs/rag/lib/python3.11/site-packages (from unsloth) (4.57.6)\n",
      "Collecting trl!=0.19.0,<=0.24.0,>=0.18.2 (from unsloth)\n",
      "  Using cached trl-0.24.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: filelock in /home/chengyi/anaconda3/envs/rag/lib/python3.11/site-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (3.20.3)\n",
      "Requirement already satisfied: pyarrow>=21.0.0 in /home/chengyi/anaconda3/envs/rag/lib/python3.11/site-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (23.0.0)\n",
      "Requirement already satisfied: dill<0.4.1,>=0.3.0 in /home/chengyi/anaconda3/envs/rag/lib/python3.11/site-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (0.4.0)\n",
      "Requirement already satisfied: pandas in /home/chengyi/anaconda3/envs/rag/lib/python3.11/site-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (3.0.0)\n",
      "Requirement already satisfied: requests>=2.32.2 in /home/chengyi/anaconda3/envs/rag/lib/python3.11/site-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (2.32.5)\n",
      "Requirement already satisfied: httpx<1.0.0 in /home/chengyi/anaconda3/envs/rag/lib/python3.11/site-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (0.28.1)\n",
      "Requirement already satisfied: xxhash in /home/chengyi/anaconda3/envs/rag/lib/python3.11/site-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (3.6.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /home/chengyi/anaconda3/envs/rag/lib/python3.11/site-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.9.0,>=2023.1.0 in /home/chengyi/anaconda3/envs/rag/lib/python3.11/site-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (2025.9.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/chengyi/anaconda3/envs/rag/lib/python3.11/site-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (6.0.3)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /home/chengyi/anaconda3/envs/rag/lib/python3.11/site-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (3.13.3)\n",
      "Requirement already satisfied: anyio in /home/chengyi/anaconda3/envs/rag/lib/python3.11/site-packages (from httpx<1.0.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (4.12.1)\n",
      "Requirement already satisfied: certifi in /home/chengyi/anaconda3/envs/rag/lib/python3.11/site-packages (from httpx<1.0.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (2026.1.4)\n",
      "Requirement already satisfied: httpcore==1.* in /home/chengyi/anaconda3/envs/rag/lib/python3.11/site-packages (from httpx<1.0.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (1.0.9)\n",
      "Requirement already satisfied: idna in /home/chengyi/anaconda3/envs/rag/lib/python3.11/site-packages (from httpx<1.0.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in /home/chengyi/anaconda3/envs/rag/lib/python3.11/site-packages (from httpcore==1.*->httpx<1.0.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (0.16.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/chengyi/anaconda3/envs/rag/lib/python3.11/site-packages (from huggingface_hub>=0.34.0->unsloth) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /home/chengyi/anaconda3/envs/rag/lib/python3.11/site-packages (from huggingface_hub>=0.34.0->unsloth) (1.2.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/chengyi/anaconda3/envs/rag/lib/python3.11/site-packages (from transformers!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,!=4.54.0,!=4.55.0,!=4.55.1,!=4.57.0,!=4.57.4,!=4.57.5,<=4.57.6,>=4.51.3->unsloth) (2026.1.15)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /home/chengyi/anaconda3/envs/rag/lib/python3.11/site-packages (from transformers!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,!=4.54.0,!=4.55.0,!=4.55.1,!=4.57.0,!=4.57.4,!=4.57.5,<=4.57.6,>=4.51.3->unsloth) (0.22.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /home/chengyi/anaconda3/envs/rag/lib/python3.11/site-packages (from transformers!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,!=4.54.0,!=4.55.0,!=4.55.1,!=4.57.0,!=4.57.4,!=4.57.5,<=4.57.6,>=4.51.3->unsloth) (0.7.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/chengyi/anaconda3/envs/rag/lib/python3.11/site-packages (from rich) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/chengyi/anaconda3/envs/rag/lib/python3.11/site-packages (from rich) (2.19.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /home/chengyi/anaconda3/envs/rag/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /home/chengyi/anaconda3/envs/rag/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/chengyi/anaconda3/envs/rag/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/chengyi/anaconda3/envs/rag/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/chengyi/anaconda3/envs/rag/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (6.7.1)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/chengyi/anaconda3/envs/rag/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/chengyi/anaconda3/envs/rag/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (1.22.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /home/chengyi/anaconda3/envs/rag/lib/python3.11/site-packages (from torch>=2.4.0->unsloth) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /home/chengyi/anaconda3/envs/rag/lib/python3.11/site-packages (from torch>=2.4.0->unsloth) (3.6.1)\n",
      "Requirement already satisfied: jinja2 in /home/chengyi/anaconda3/envs/rag/lib/python3.11/site-packages (from torch>=2.4.0->unsloth) (3.1.6)\n",
      "Requirement already satisfied: cuda-bindings==12.9.4 in /home/chengyi/anaconda3/envs/rag/lib/python3.11/site-packages (from torch>=2.4.0->unsloth) (12.9.4)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /home/chengyi/anaconda3/envs/rag/lib/python3.11/site-packages (from torch>=2.4.0->unsloth) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /home/chengyi/anaconda3/envs/rag/lib/python3.11/site-packages (from torch>=2.4.0->unsloth) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /home/chengyi/anaconda3/envs/rag/lib/python3.11/site-packages (from torch>=2.4.0->unsloth) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /home/chengyi/anaconda3/envs/rag/lib/python3.11/site-packages (from torch>=2.4.0->unsloth) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /home/chengyi/anaconda3/envs/rag/lib/python3.11/site-packages (from torch>=2.4.0->unsloth) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /home/chengyi/anaconda3/envs/rag/lib/python3.11/site-packages (from torch>=2.4.0->unsloth) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /home/chengyi/anaconda3/envs/rag/lib/python3.11/site-packages (from torch>=2.4.0->unsloth) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /home/chengyi/anaconda3/envs/rag/lib/python3.11/site-packages (from torch>=2.4.0->unsloth) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /home/chengyi/anaconda3/envs/rag/lib/python3.11/site-packages (from torch>=2.4.0->unsloth) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /home/chengyi/anaconda3/envs/rag/lib/python3.11/site-packages (from torch>=2.4.0->unsloth) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /home/chengyi/anaconda3/envs/rag/lib/python3.11/site-packages (from torch>=2.4.0->unsloth) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.4.5 in /home/chengyi/anaconda3/envs/rag/lib/python3.11/site-packages (from torch>=2.4.0->unsloth) (3.4.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /home/chengyi/anaconda3/envs/rag/lib/python3.11/site-packages (from torch>=2.4.0->unsloth) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /home/chengyi/anaconda3/envs/rag/lib/python3.11/site-packages (from torch>=2.4.0->unsloth) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /home/chengyi/anaconda3/envs/rag/lib/python3.11/site-packages (from torch>=2.4.0->unsloth) (1.13.1.3)\n",
      "Requirement already satisfied: cuda-pathfinder~=1.1 in /home/chengyi/anaconda3/envs/rag/lib/python3.11/site-packages (from cuda-bindings==12.9.4->torch>=2.4.0->unsloth) (1.3.3)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/chengyi/anaconda3/envs/rag/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich) (0.1.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/chengyi/anaconda3/envs/rag/lib/python3.11/site-packages (from requests>=2.32.2->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/chengyi/anaconda3/envs/rag/lib/python3.11/site-packages (from requests>=2.32.2->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (2.6.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/chengyi/anaconda3/envs/rag/lib/python3.11/site-packages (from sympy>=1.13.3->torch>=2.4.0->unsloth) (1.3.0)\n",
      "Requirement already satisfied: torchao>=0.13.0 in /home/chengyi/anaconda3/envs/rag/lib/python3.11/site-packages (from unsloth_zoo>=2026.1.4->unsloth) (0.15.0)\n",
      "Requirement already satisfied: cut_cross_entropy in /home/chengyi/anaconda3/envs/rag/lib/python3.11/site-packages (from unsloth_zoo>=2026.1.4->unsloth) (25.1.1)\n",
      "Requirement already satisfied: pillow in /home/chengyi/anaconda3/envs/rag/lib/python3.11/site-packages (from unsloth_zoo>=2026.1.4->unsloth) (12.1.0)\n",
      "Requirement already satisfied: msgspec in /home/chengyi/anaconda3/envs/rag/lib/python3.11/site-packages (from unsloth_zoo>=2026.1.4->unsloth) (0.20.0)\n",
      "Requirement already satisfied: importlib_metadata in /home/chengyi/anaconda3/envs/rag/lib/python3.11/site-packages (from diffusers->unsloth) (8.7.1)\n",
      "Requirement already satisfied: zipp>=3.20 in /home/chengyi/anaconda3/envs/rag/lib/python3.11/site-packages (from importlib_metadata->diffusers->unsloth) (3.23.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/chengyi/anaconda3/envs/rag/lib/python3.11/site-packages (from jinja2->torch>=2.4.0->unsloth) (3.0.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/chengyi/anaconda3/envs/rag/lib/python3.11/site-packages (from pandas->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /home/chengyi/anaconda3/envs/rag/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (1.17.0)\n",
      "Requirement already satisfied: docstring-parser>=0.15 in /home/chengyi/anaconda3/envs/rag/lib/python3.11/site-packages (from tyro->unsloth) (0.17.0)\n",
      "Requirement already satisfied: typeguard>=4.0.0 in /home/chengyi/anaconda3/envs/rag/lib/python3.11/site-packages (from tyro->unsloth) (4.4.4)\n",
      "Using cached trl-0.24.0-py3-none-any.whl (423 kB)\n",
      "Using cached xformers-0.0.34-cp39-abi3-manylinux_2_28_x86_64.whl (110.8 MB)\n",
      "Installing collected packages: xformers, trl\n",
      "\u001b[2K  Attempting uninstall: xformers\n",
      "\u001b[2K    Found existing installation: xformers 0.0.26.post1\n",
      "\u001b[2K    Uninstalling xformers-0.0.26.post1:\n",
      "\u001b[2K      Successfully uninstalled xformers-0.0.26.post1\n",
      "\u001b[2K  Attempting uninstall: trl笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m0/2\u001b[0m [xformers]\n",
      "\u001b[2K    Found existing installation: trl 0.8.6笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m0/2\u001b[0m [xformers]\n",
      "\u001b[2K    Uninstalling trl-0.8.6:笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m0/2\u001b[0m [xformers]\n",
      "\u001b[2K      Successfully uninstalled trl-0.8.6笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m0/2\u001b[0m [xformers]\n",
      "\u001b[2K   \u001b[38;2;114;156;31m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m2/2\u001b[0m [trl]笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m1/2\u001b[0m [trl]\n",
      "\u001b[1A\u001b[2KSuccessfully installed trl-0.24.0 xformers-0.0.34\n",
      "Collecting xformers<0.0.27\n",
      "  Using cached xformers-0.0.26.post1-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.0 kB)\n",
      "Collecting trl<0.9.0\n",
      "  Using cached trl-0.8.6-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: peft in /home/chengyi/anaconda3/envs/rag/lib/python3.11/site-packages (0.18.1)\n",
      "Requirement already satisfied: accelerate in /home/chengyi/anaconda3/envs/rag/lib/python3.11/site-packages (1.12.0)\n",
      "Requirement already satisfied: bitsandbytes in /home/chengyi/anaconda3/envs/rag/lib/python3.11/site-packages (0.49.1)\n",
      "Using cached xformers-0.0.26.post1-cp311-cp311-manylinux2014_x86_64.whl (222.8 MB)\n",
      "Using cached trl-0.8.6-py3-none-any.whl (245 kB)\n",
      "Installing collected packages: xformers, trl\n",
      "\u001b[2K  Attempting uninstall: xformers\n",
      "\u001b[2K    Found existing installation: xformers 0.0.34\n",
      "\u001b[2K    Uninstalling xformers-0.0.34:\n",
      "\u001b[2K      Successfully uninstalled xformers-0.0.34\n",
      "\u001b[2K  Attempting uninstall: trl笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m0/2\u001b[0m [xformers]\n",
      "\u001b[2K    Found existing installation: trl 0.24.0笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m0/2\u001b[0m [xformers]\n",
      "\u001b[2K    Uninstalling trl-0.24.0:笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m0/2\u001b[0m [xformers]\n",
      "\u001b[2K      Successfully uninstalled trl-0.24.0笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m0/2\u001b[0m [xformers]\n",
      "\u001b[2K   \u001b[38;2;114;156;31m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m2/2\u001b[0m [trl]笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m1/2\u001b[0m [trl]\n",
      "\u001b[1A\u001b[2KSuccessfully installed trl-0.8.6 xformers-0.0.26.post1\n"
     ]
    }
   ],
   "source": [
    "!pip install unsloth rich\n",
    "!pip install --no-deps \"xformers<0.0.27\" \"trl<0.9.0\" peft accelerate bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4250c4ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "洶･ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chengyi/anaconda3/envs/rag/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "洶･ Unsloth Zoo will now patch everything to make training faster!\n",
      "Unsloth: Could not import trl.trainer.ddpo_trainer: Failed to import trl.trainer.ddpo_trainer because of the following error (look up to see its traceback):\n",
      "Failed to import trl.models.modeling_sd_base because of the following error (look up to see its traceback):\n",
      "Failed to import diffusers.pipelines.stable_diffusion.pipeline_stable_diffusion because of the following error (look up to see its traceback):\n",
      "Failed to import diffusers.loaders.ip_adapter because of the following error (look up to see its traceback):\n",
      "'NoneType' object has no attribute 'start'\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from unsloth.chat_templates import get_chat_template\n",
    "from unsloth import FastLanguageModel, is_bfloat16_supported\n",
    "from trl import SFTTrainer\n",
    "from datasets import load_dataset, Dataset\n",
    "from transformers import TrainingArguments, TextStreamer, DataCollatorForLanguageModeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd0f969",
   "metadata": {},
   "source": [
    "# Initialize model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6df6539d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2026.1.4: Fast Llama patching. Transformers: 4.57.6.\n",
      "   \\\\   /|    NVIDIA GeForce RTX 5060 Ti. Num GPUs = 1. Max memory: 15.474 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.10.0+cu128. CUDA: 12.0. CUDA Toolkit: 12.8. Triton: 3.6.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = None. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    }
   ],
   "source": [
    "# Load model\n",
    "max_seq_length = 2048\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name=\"unsloth/Llama-3.2-3B-Instruct\",\n",
    "    max_seq_length=max_seq_length,\n",
    "    load_in_4bit=True,\n",
    "    dtype=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a645507",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth 2026.1.4 patched 28 layers with 28 QKV layers, 28 O layers and 28 MLP layers.\n"
     ]
    }
   ],
   "source": [
    "# Initialize LoRA\n",
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r=16,\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0,\n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"up_proj\", \"down_proj\", \"o_proj\", \"gate_proj\"], \n",
    "    use_rslora=True,\n",
    "    use_gradient_checkpointing=\"unsloth\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ed39b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth: Will map <|im_end|> to EOS = <|eot_id|>.\n"
     ]
    }
   ],
   "source": [
    "# Initialize chat template (for instruction tuning)\n",
    "tokenizer = get_chat_template(\n",
    "    tokenizer,\n",
    "    mapping={\"role\": \"from\", \"content\": \"value\", \"user\": \"human\", \"assistant\": \"gpt\"},\n",
    "    chat_template=\"chatml\",\n",
    ")\n",
    "\n",
    "def apply_template(examples):\n",
    "    messages = examples[\"conversations\"]\n",
    "    text = [tokenizer.apply_chat_template(message, tokenize=False, add_generation_prompt=False) for message in messages]\n",
    "    return {\"text\": text}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1163001f",
   "metadata": {},
   "source": [
    "If we do causal language modeling, we don't need the chat template."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73bc9c3f",
   "metadata": {},
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fdee586",
   "metadata": {},
   "source": [
    "The original data in the tutorial had 3 features: `['conversations', 'source', 'score']`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ab15fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "Example of original_data['conversations'][example]\n",
    "[{'from': 'human',\n",
    "  'value': 'user_message'},\n",
    " {'from': 'gpt',\n",
    "  'value': 'preferred_response'}]\n",
    "\n",
    "Example of original_data['source'][example]\n",
    "'source'\n",
    "\n",
    "Example of original_data['score'][example]\n",
    "floating point 3.7 to 5.2\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0acabbaa",
   "metadata": {},
   "source": [
    "Once we map the aply_template function, we get an extra column `text`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14328c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "Example of original_data['text'][example]\n",
    "<|im_start|>user\n",
    "user_message<|im_end|>\n",
    "<|im_start|>assistant\n",
    "preferred_response<|im_end|>\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "28bd1e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in causal fine-tuning dataset\n",
    "import pandas as pd\n",
    "\n",
    "info_data = pd.read_csv('../Code/dataset.csv').set_index(\"Unnamed: 0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "23d1852e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset size: 21412\n",
      "\n",
      "=== Data Quality Check ===\n",
      "Data types:\n",
      "context          str\n",
      "target_prefix    str\n",
      "target_suffix    str\n",
      "dtype: object\n",
      "\n",
      "Null values:\n",
      "context          236\n",
      "target_prefix      0\n",
      "target_suffix    103\n",
      "dtype: int64\n",
      "\n",
      "Empty strings:\n",
      "0 empty contexts\n",
      "0 empty prefixes\n",
      "0 empty suffixes\n",
      "\n",
      "Dataset size after cleaning: 21073\n",
      "Removed 339 bad rows\n"
     ]
    }
   ],
   "source": [
    "# Check for NA values\n",
    "print(f\"Original dataset size: {len(info_data)}\")\n",
    "\n",
    "print(\"\\n=== Data Quality Check ===\")\n",
    "print(\"Data types:\")\n",
    "print(info_data[['context', 'target_prefix', 'target_suffix']].dtypes)\n",
    "\n",
    "print(\"\\nNull values:\")\n",
    "print(info_data[['context', 'target_prefix', 'target_suffix']].isnull().sum())\n",
    "\n",
    "print(\"\\nEmpty strings:\")\n",
    "print((info_data['context'] == '').sum(), \"empty contexts\")\n",
    "print((info_data['target_prefix'] == '').sum(), \"empty prefixes\")\n",
    "print((info_data['target_suffix'] == '').sum(), \"empty suffixes\")\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"Clean and validate text\"\"\"\n",
    "    if pd.isna(text):\n",
    "        return None\n",
    "    if not isinstance(text, str):\n",
    "        text = str(text)\n",
    "    text = text.strip()\n",
    "    if len(text) == 0:\n",
    "        return None\n",
    "    return text\n",
    "\n",
    "# Apply cleaning\n",
    "info_data['context_clean'] = info_data['context'].apply(clean_text)\n",
    "info_data['prefix_clean'] = info_data['target_prefix'].apply(clean_text)\n",
    "info_data['suffix_clean'] = info_data['target_suffix'].apply(clean_text)\n",
    "\n",
    "info_data_clean = info_data[\n",
    "    (info_data['context_clean'].notna()) &\n",
    "    (info_data['prefix_clean'].notna()) &\n",
    "    (info_data['suffix_clean'].notna())\n",
    "].copy()\n",
    "\n",
    "print(f\"\\nDataset size after cleaning: {len(info_data_clean)}\")\n",
    "print(f\"Removed {len(info_data) - len(info_data_clean)} bad rows\")\n",
    "\n",
    "info_data_clean['text'] = (\n",
    "    info_data_clean['context_clean'] + \" \" + \n",
    "    info_data_clean['prefix_clean'] + \n",
    "    info_data_clean['suffix_clean']\n",
    ")\n",
    "\n",
    "dataset = Dataset.from_dict({\n",
    "    'text': info_data_clean['text'].astype(str).tolist()\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2d76342f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=2): 100%|笆遺毎笆遺毎笆遺毎笆遺毎笆遺毎| 21073/21073 [00:11<00:00, 1873.59 examples/s]\n",
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
      "   \\\\   /|    Num examples = 21,073 | Num Epochs = 4 | Total steps = 5,000\n",
      "O^O/ \\_/ \\    Batch size per device = 2 | Gradient accumulation steps = 8\n",
      "\\        /    Data Parallel GPUs = 1 | Total batch size (2 x 8 x 1) = 16\n",
      " \"-____-\"     Trainable parameters = 24,313,856 of 3,237,063,680 (0.75% trained)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5000' max='5000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5000/5000 5:43:07, Epoch 3/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.816900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.779800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1.801800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>1.860300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.817000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>1.861900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>1.814700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>1.805500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>1.742100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.770700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>1.823600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>1.759400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>1.828500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>1.644300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>1.603600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>1.542600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>1.634900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>1.597400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>1.617800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>1.591300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>1.579200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>1.594800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>1.630700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>1.606600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>1.624700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>1.589100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>1.433300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>1.334600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>1.331600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>1.391900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3100</td>\n",
       "      <td>1.318300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>1.304600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3300</td>\n",
       "      <td>1.315800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>1.343800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>1.310200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>1.321500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3700</td>\n",
       "      <td>1.426100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>1.385700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3900</td>\n",
       "      <td>1.368100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>1.173400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4100</td>\n",
       "      <td>1.088500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>1.071200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4300</td>\n",
       "      <td>1.080300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4400</td>\n",
       "      <td>1.104000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>1.089400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4600</td>\n",
       "      <td>1.063600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4700</td>\n",
       "      <td>1.092800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>1.081700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4900</td>\n",
       "      <td>1.070900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>1.088400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=5000, training_loss=1.4785772811889648, metrics={'train_runtime': 20592.5612, 'train_samples_per_second': 3.885, 'train_steps_per_second': 0.243, 'total_flos': 5.958967103684813e+17, 'train_loss': 1.4785772811889648, 'epoch': 3.7941539337572365})"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "model.gradient_checkpointing_enable()\n",
    "\n",
    "trainer=SFTTrainer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    train_dataset=dataset,\n",
    "    dataset_text_field=\"text\",\n",
    "    max_seq_length=1024,\n",
    "    dataset_num_proc=2,\n",
    "    packing=False,\n",
    "    args=TrainingArguments(\n",
    "        learning_rate=3e-4,\n",
    "        lr_scheduler_type=\"linear\",\n",
    "        per_device_train_batch_size=2,\n",
    "        gradient_accumulation_steps=8, # A batch is effectively per_device_batch_size * gradient_accummulation_steps\n",
    "        max_steps=5000,\n",
    "        fp16=not is_bfloat16_supported(),\n",
    "        bf16=is_bfloat16_supported(),\n",
    "        logging_steps=100,\n",
    "        optim=\"paged_adamw_8bit\",\n",
    "        weight_decay=0.01,\n",
    "        warmup_steps=100,\n",
    "        output_dir=\"output\",\n",
    "        seed=0,\n",
    "        save_steps=500,\n",
    "        gradient_checkpointing=True,\n",
    "    ),\n",
    ")\n",
    "\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "152009d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Files (3 / 3): 100%|笆遺毎笆遺毎笆遺毎笆遺毎笆遺毎|  115MB /  115MB, 5.92MB/s  \n",
      "New Data Upload: 100%|笆遺毎笆遺毎笆遺毎笆遺毎笆遺毎|  114MB /  114MB, 5.92MB/s  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/chengyili2005/output/commit/5f68f9c439ea72e98a07d5496e30abac1d9f895b', commit_message='End of training', commit_description='', oid='5f68f9c439ea72e98a07d5496e30abac1d9f895b', pr_url=None, repo_url=RepoUrl('https://huggingface.co/chengyili2005/output', endpoint='https://huggingface.co', repo_type='model', repo_id='chengyili2005/output'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kwargs = {\n",
    "    \"dataset_tags\": \"wikimedia/wikipedia\",\n",
    "    \"dataset\": \"psgs_w100\",\n",
    "    \"dataset_args\": \"config: wikipedia, split: train\",\n",
    "    \"language\": \"en\",\n",
    "    \"model_name\": \"Llama-3.2-3B-Instruct InfoRag - Chengyi Li\",\n",
    "    \"finetuned_from\": \"unsloth/Llama-3.2-3B-Instruct\",\n",
    "    \"tasks\": \"causal-language-modeling\",\n",
    "}\n",
    "trainer.push_to_hub(**kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7307744c",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0dfc3cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../')\n",
    "\n",
    "from evaluation_pipeline import Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "662447a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|笆遺毎笆遺毎笆遺毎笆遺毎笆遺毎| 2/2 [00:04<00:00,  2.33s/it]\n",
      "Device set to use cuda:0\n",
      "Device set to use cuda:0\n",
      "Generating train split: 100%|笆遺毎笆遺毎笆遺毎笆遺毎笆遺毎| 9223/9223 [00:00<00:00, 143621.14 examples/s]\n",
      "Generating test split: 100%|笆遺毎笆遺毎笆遺毎笆遺毎笆遺毎| 2306/2306 [00:00<00:00, 173695.59 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import pipeline, BitsAndBytesConfig\n",
    "import torch\n",
    "\n",
    "# Load models\n",
    "base_llm = pipeline('text-generation', model='unsloth/Llama-3.2-3B-Instruct', device_map='auto', model_kwargs={'quantization_config':BitsAndBytesConfig(load_in_8bit=True), 'dtype':torch.float16})\n",
    "tuned_llm = pipeline('text-generation', model='chengyili2005/Llama-3.2-3B-Instruct-InfoRAG', device_map='auto', model_kwargs={'quantization_config':BitsAndBytesConfig(load_in_8bit=True), 'dtype':torch.float16})\n",
    "\n",
    "# Load datasets\n",
    "hotpot_dataset = load_dataset('hotpotqa/hotpot_qa', 'distractor', split='validation')\n",
    "wow_dataset = load_dataset('Organika/wizard_of_wikipedia', split='test')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b6677c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess functions to be fed into evaluator\n",
    "def preprocess_hotpot(example):\n",
    "    context_parts = []\n",
    "    for title, sentences in zip(example['context']['title'], example['context']['sentences']):\n",
    "        context_parts.append(f\"{title}: {' '.join(sentences)}\")\n",
    "    return {\n",
    "        'question' : example['question'],\n",
    "        'answer': example['answer'],\n",
    "        'context': ' '.join(context_parts)\n",
    "    }\n",
    "def preprocess_wow(example):\n",
    "    return {\n",
    "        'context': example['persona'],\n",
    "        'question': \"You have just met the other person, who seems quite curious, and you are eager to discuss a topic with them!\", # https://ar5iv.labs.arxiv.org/html/1811.01241 I got the prompt from here\n",
    "        'answer': example['text']\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b61316a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup evaluators\n",
    "hotpot_template = \"Context: {context}\\n\\nQuestion: {question}\\n\\nAnswer:\"\n",
    "hotpot_evaluator = Evaluator(\n",
    "    prompt_template=hotpot_template,\n",
    "    question_key='question',\n",
    "    answer_key='answer',\n",
    "    context_key='context'\n",
    ")\n",
    "wow_template = \"Context: {context}\\n\\nConversation: {question}\\n\\nAnswer:\"\n",
    "wow_evaluator = Evaluator(\n",
    "    prompt_template=wow_template,\n",
    "    question_key='question',\n",
    "    answer_key='answer',\n",
    "    context_key='context'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c8a425",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HotpotQA - EM: 0.0400, F1: 0.1333\n"
     ]
    }
   ],
   "source": [
    "# Run evaluation\n",
    "em, f1 = hotpot_evaluator.evaluation(\n",
    "    llm=base_llm,\n",
    "    dataset=hotpot_dataset,\n",
    "    model_name='base-model-hotpot',\n",
    "    preprocess_fn=preprocess_hotpot,\n",
    "    max_samples=100\n",
    ")\n",
    "print(f\"Base HotpotQA - EM: {em:.4f}, F1: {f1:.4f}\")\n",
    "em, f1 = hotpot_evaluator.evaluation(\n",
    "    llm=tuned_llm,\n",
    "    dataset=hotpot_dataset,\n",
    "    model_name='tuned-model-hotpot',\n",
    "    preprocess_fn=preprocess_hotpot,\n",
    "    max_samples=100\n",
    ")\n",
    "print(f\"Tuned HotpotQA - EM: {em:.4f}, F1: {f1:.4f}\")\n",
    "em, f1 = wow_evaluator.evaluation(\n",
    "    llm=base_llm,\n",
    "    dataset=wow_dataset,\n",
    "    model_name='base-model-wow',\n",
    "    preprocess_fn=preprocess_wow,\n",
    "    max_samples=100\n",
    ")\n",
    "print(f\"Base WoW - EM: {em:.4f}, F1: {f1:.4f}\")\n",
    "em, f1 = wow_evaluator.evaluation(\n",
    "    llm=tuned_llm,\n",
    "    dataset=wow_dataset,\n",
    "    model_name='tuned-model-wow',\n",
    "    preprocess_fn=preprocess_wow,\n",
    "    max_samples=100\n",
    ")\n",
    "print(f\"Tuned WoW - EM: {em:.4f}, F1: {f1:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
